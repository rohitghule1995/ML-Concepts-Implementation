{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "# !pip  install tensorflow\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "# Create a DataFrame for the features\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "# df['target'] = iris.target\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.DataFrame()\n",
    "targets['target'] = iris.target\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, targets, test_size=0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Neural_Network:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.input_nodes**-0.5, \n",
    "                                                        (self.input_nodes, self.hidden_nodes))\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.hidden_nodes**-0.5,\n",
    "                                                         (self.hidden_nodes, self.output_nodes))\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.activation_function = lambda x: 1/(1+np.exp(-x))\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden_inputs = np.dot(X, self.weights_input_to_hidden)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output)\n",
    "        final_outputs = self.activation_function(final_inputs) \n",
    "\n",
    "        return hidden_outputs, final_outputs\n",
    "    \n",
    "    def backward_prop(self, hidden_outputs, final_outputs, X, Y, delta_weights_i_h, delta_weights_h_o):\n",
    "        error = Y - final_outputs\n",
    "        hidden_error = np.dot(self.weights_hidden_to_output,error)\n",
    "        output_error_term = error * final_outputs * (1-final_outputs)\n",
    "        hidden_error_term = hidden_error * hidden_outputs * (1-hidden_outputs)\n",
    "\n",
    "        delta_weights_h_o += output_error_term*hidden_outputs[:,None]\n",
    "        delta_weights_i_h += hidden_error_term*X[:,None]\n",
    "\n",
    "        return delta_weights_i_h, delta_weights_h_o\n",
    "    \n",
    "    def update_weights(self, delta_weights_i_h, delta_weights_h_o, n_records):\n",
    "        self.weights_input_to_hidden+=self.lr*delta_weights_i_h/n_records\n",
    "        self.weights_hidden_to_output+=self.lr*delta_weights_h_o/n_records\n",
    "\n",
    "    def train(self, features, targets):\n",
    "        n_records = features.shape[0]\n",
    "        delta_weights_i_h = np.zeros(self.weights_input_to_hidden.shape)\n",
    "        delta_weights_h_o = np.zeros(self.weights_hidden_to_output.shape)\n",
    "\n",
    "        for X,Y in zip(features,targets):\n",
    "            hidden_output, final_output = self.forward(X)\n",
    "            delta_weights_i_h, delta_weights_h_o = self.backward_prop(hidden_output,\n",
    "                                                                      final_output,\n",
    "                                                                      X,\n",
    "                                                                      Y,\n",
    "                                                                      delta_weights_i_h,\n",
    "                                                                      delta_weights_h_o)\n",
    "        self.update_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n",
    "\n",
    "    def predict(self, features):\n",
    "        hidden_inputs = np.dot(features, self.weights_input_to_hidden)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(hidden_outputs, self.weights_hidden_to_output)\n",
    "        final_outputs = final_inputs\n",
    "\n",
    "        return final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations=100\n",
    "learning_rate=0.01\n",
    "hidden_nodes=2\n",
    "output_nodes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y,Y):\n",
    "  return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.29244214]\n",
      " [-0.10709219]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.021s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "inputs = np.array([[0.5, -0.2, 0.1]])\n",
    "targets = np.array([[0.4]])\n",
    "\n",
    "test_w_i_h = np.array([[0.1, -0.2],\n",
    "                       [0.4, 0.5],\n",
    "                       [-0.3, 0.2]])\n",
    "test_w_h_o = np.array([[0.3],\n",
    "                       [-0.1]])\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "        \n",
    "    def test_data_loaded(self):\n",
    "        # Test that data frame loaded\n",
    "        self.assertTrue(isinstance(df, pd.DataFrame))\n",
    "\n",
    "    def test_activation(self):\n",
    "        network = MLP_Neural_Network(3, 2, 1, 0.5)\n",
    "        # Test that the activation function is a sigmoid\n",
    "        self.assertTrue(np.all(network.activation_function(0.5) == 1/(1+np.exp(-0.5))))\n",
    "\n",
    "    def test_train(self):\n",
    "        # Test that weights are updated correctly on training\n",
    "        network = MLP_Neural_Network(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "        \n",
    "        network.train(inputs, targets)\n",
    "        print(network.weights_hidden_to_output)\n",
    "        self.assertTrue(np.allclose(network.weights_hidden_to_output, \n",
    "                                    np.array([[ 0.29244214], \n",
    "                                              [-0.10709219]])))\n",
    "        self.assertTrue(np.allclose(network.weights_input_to_hidden,\n",
    "                                    np.array([[ 0.10562014, -0.20185996], \n",
    "                                              [0.39775194, 0.50074398], \n",
    "                                              [-0.29887597, 0.19962801]]),rtol=1.0))\n",
    "    def test_run(self):\n",
    "        # Test correctness of run method\n",
    "        network = MLP_Neural_Network(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "\n",
    "        self.assertTrue(np.allclose(network.predict(inputs), 0.09998924))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestMethods())\n",
    "unittest.TextTestRunner().run(suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 28 48 48 17  5 85 49 71 61 69 22 19  8 23 30 67 37 70 49 72 83 17  0\n",
      " 47 40 60 59 30 21 84 27]\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U6'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(batch)\n\u001b[1;32m      9\u001b[0m X,y\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39miloc[batch]\u001b[38;5;241m.\u001b[39mvalues, Y_train\u001b[38;5;241m.\u001b[39miloc[batch]\n\u001b[0;32m---> 10\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m MSE(network\u001b[38;5;241m.\u001b[39mrun(X_train)\u001b[38;5;241m.\u001b[39mT, Y_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     13\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m MSE(network\u001b[38;5;241m.\u001b[39mrun(X_test)\u001b[38;5;241m.\u001b[39mT, Y_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m, in \u001b[0;36mMLP_Neural_Network.train\u001b[0;34m(self, features, targets)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X,Y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(features,targets):\n\u001b[1;32m     45\u001b[0m     hidden_output, final_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[0;32m---> 46\u001b[0m     delta_weights_i_h, delta_weights_h_o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_prop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mfinal_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mdelta_weights_i_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mdelta_weights_h_o\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_weights(delta_weights_i_h, delta_weights_h_o, n_records)\n",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m, in \u001b[0;36mMLP_Neural_Network.backward_prop\u001b[0;34m(self, hidden_outputs, final_outputs, X, Y, delta_weights_i_h, delta_weights_h_o)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_prop\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_outputs, final_outputs, X, Y, delta_weights_i_h, delta_weights_h_o):\n\u001b[0;32m---> 25\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[43mY\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfinal_outputs\u001b[49m\n\u001b[1;32m     26\u001b[0m     hidden_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights_hidden_to_output,error)\n\u001b[1;32m     27\u001b[0m     output_error_term \u001b[38;5;241m=\u001b[39m error \u001b[38;5;241m*\u001b[39m final_outputs \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mfinal_outputs)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U6'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "N_i=X_train.shape[1]\n",
    "network=MLP_Neural_Network(N_i,hidden_nodes,output_nodes,learning_rate)\n",
    "\n",
    "losses={'train':[], 'validation':[]}\n",
    "for ii in range(3):\n",
    "    batch=np.random.choice(X_train.index,size=32)\n",
    "    X,y=X_train.iloc[batch].values, Y_train.iloc[batch]\n",
    "    network.train(X,y)\n",
    "\n",
    "    train_loss = MSE(network.run(X_train).T, Y_train['target'].values)\n",
    "    val_loss = MSE(network.run(X_test).T, Y_test['target'].values)\n",
    "    sys.stdout.write(\"\\rProgress: {:2.1f}\".format(100 * ii/float(iterations)) \\\n",
    "                    + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                    + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
